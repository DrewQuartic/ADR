#-------------------------------------------------------------------------------
# Name:        LoadFromLocal.py
# Purpose:      Takes the list of FCs to be updated that was generated by the
#               DownloadBackup.py script and loads them into SDE. It first tries a copy and past operation
#               So indexes will be preserved. If this fails due to inconsistent spatial domains in the parent DS
#               the script resorts to import using the FCtoFC tool. It then manually creats the indexes.
#               Finally the script updates the layers_update_table.
#
# Author:      DDowling
#
# Created:     27/09/2013
# Copyright:   (c) DDowling 2013
#
#-------------------------------------------------------------------------------
import arcpy, sys, os, ConfigParser
#import logging.config
import datetime, time
import emailsender,killusers

# Setup Logging
logFile = open("D:\BATCH_FILES\ADR\GDBDeploy_LOG.txt", "wb")
#layerlogFile = open("D:\BATCH_FILES\ADR\GDBLoad_LAYERLOG.txt", "wb")

# Read Configuration File
config = ConfigParser.ConfigParser()
config.read("D:\BATCH_FILES\ADR\GDBLoad.ini")

SDEGDB = config.get('paths', 'localGDB')
AdminGDB = config.get('paths', 'AdminGDB')
Staging_NEW = config.get('paths', 'Staging_NEW')
Staging_BAK = config.get('paths', 'Staging_BAK')
deploylist = config.get('paths', 'deploylist')
localDataset = config.get('paths', 'localDataset')
schema = config.get('names', 'schema')
sde_keyword = config.get('names', 'sde_keyword')
responsible_party_str = config.get('names', 'responsible_party_list')
responsible_party_list = responsible_party_str.split(',')
updateTable = config.get('paths', 'updateTable')



def main():
    try:
        startTime = datetime.datetime.today()
        startCheckTime = time.time()
        strstartTime = startTime.strftime("%I:%M%p on %B %d, %Y")
        logFile.write ("\n" + "-----------------Beginning Deploy Job---------------")
        logFile.write ("\n" + "Started at:" + strstartTime)
        logFile.write ("\n")
        logFile.flush()
        arcpy.env.transferDomains = True
        arcpy.env.overwriteOutput = True
        fileloadlist = open(deploylist)
        lstloadlist = fileloadlist.readlines()
        killusers.dropAllUsers()
        #arcpy.env.workspace = SDEGDB
        for loaditem in lstloadlist:
            print loaditem
            logFile.write ("\n" + "*******Sarting load of {0}******* \n".format(loaditem.rstrip()))
            logFile.flush()
            itemNamelist = loaditem.split("\\")
            itemName = itemNamelist[len(itemNamelist) -1].rstrip()
            arcpy.env.workspace = ""
            killusers.dropOtherUsers()
            arcpy.env.workspace = SDEGDB
            expression = arcpy.AddFieldDelimiters(updateTable, 'SANGIS_LAYER_NAME') + " = '" + itemName + "'"
            logFile.write("looking up update table using: {0} \n".format(expression))
            logFile.flush()
            try:
                with arcpy.da.SearchCursor(updateTable,['Dataset','RESPONSIBLE_DEPARTMENT','CITY_LAYER_NAME','SANGIS_LAYER_NAME'], where_clause=  expression) as cursor:
                    for row in cursor:
                        if arcpy.Exists(loaditem):
                            #use the city_layer_name value as the name of the loaded table. However if the load item is new this week then the city_layer_name will be null
                            #in this case use the sangis_name
                            if row[2] is None:
                                FCLoadName = row[3]
                            else:
                                FCLoadName = row[2]
                            desc = arcpy.Describe(loaditem)
                            if desc.dataType == "FeatureClass":
                                #arcpy.FeatureClassToFeatureClass_conversion(loaditem,SDEGDB + "\\" + row[0], row[2])
                                arcpy.Copy_management(loaditem,SDEGDB + "\\" + row[0] + "\\" + FCLoadName)
                            elif desc.dataType == "Table":
                                arcpy.TableToTable_conversion(loaditem,SDEGDB, FCLoadName)
                                #arcpy.Copy_management(loaditem,SDEGDB + "\\" + row[0] + "\\" + row[2])
                            elif desc.dataType == "FeatureDataset":
                                #check to see if the dataset already exists in SDE, if so delete it and its related tables, if not just do a copy
                                if arcpy.Exists(SDEGDB + "\\" + FCLoadName):
                                    #arcpy.Delete_management(SDEGDB + "\\" + FCLoadName)
                                    rc_list = [c.name for c in arcpy.Describe(SDEGDB + "\\" + FCLoadName).children if c.datatype == "RelationshipClass"]
                                    for rc in rc_list:
                                        rc_path = SDEGDB + "\\" + rc
                                        des_rc = arcpy.Describe(rc_path)
                                        destination = des_rc.destinationClassNames
                                        for item in destination:
                                            arcpy.Delete_management(SDEGDB  + "\\" +  item)
                                        #TODO - delete destination tables and FCs before load of new Dataset
                                    arcpy.Delete_management(SDEGDB + "\\" + FCLoadName)
                                arcpy.Copy_management(loaditem,SDEGDB + "\\" + FCLoadName)
                            print arcpy.GetMessages()
                            del desc
                            logFile.write ( arcpy.GetMessages() + "\n")
                            logFile.flush()
                        else:
                            logFile.write("problem loading {0}. Not found in staging area".format(loaditem) + "\n")
                            logFile.flush()
                    del row
                del cursor
                #Update cursor to update layer_update table will go here
            except arcpy.ExecuteError:
                spatialerror =  arcpy.GetMessages(2).find("ERROR 000260")
                if spatialerror > -1:
                    try:
                        print arcpy.GetMessages()
                        logFile.write("failed Copy and past import of {0} due to spatial domain differences. Attempting an import".format(loaditem))
                        arcpy.FeatureClassToFeatureClass_conversion(loaditem,SDEGDB + "\\" + row[0], row[2])
                        logFile.write ( arcpy.GetMessages() + "\n")
                        logFile.flush()
                        skipList = ["OBJECTID", "SHAPE", "SHAPE.Area", "SHAPE.Length", "SHAPE.STArea()","SHAPE.STLength()"]
                        fieldList = arcpy.ListFields(SDEGDB + "\\" + row[0] + "\\" + row[2])
                        for field in fieldList:
                            if not field.name in skipList:
                                print "Indexing: " + field.name
                                killusers.dropOtherUsers()
                                arcpy.AddIndex_management(SDEGDB + "\\" + row[0] + "\\" +  row[2], field.name, row[2] + field.name)
                    except:
                        logFile.write("failed FeatureClassToFeatureClass import or indexing of {0}".format(loaditem))
                        logFile.write ( arcpy.GetMessages() + "\n")
                        logFile.flush()
                else:
                    logFile.write(arcpy.GetMessages() + "\n")
            except Exception, err:
                logFile.write (str(err) + "\n" +  arcpy.GetMessages() + "\n")
                logFile.flush()
        print arcpy.GetMessages()
    except Exception, err:
        print err
        logFile.write (str(err) + "\n" +  arcpy.GetMessages()+ "\n")
        logFile.flush()
        emailsender.main("load_notify@sddpc.org","x","Deploy err: {0}".format(loaditem),str(err) + "\n" +  arcpy.GetMessages(),"True")
    finally:
        arcpy.AcceptConnections(AdminGDB, True)

if __name__ == '__main__':
    main()
